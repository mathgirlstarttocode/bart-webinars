{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MIGYtH14DwXD"
   },
   "source": [
    "# BART Webinar: A deep dive into 3D Cartesian reconstruction with BART\n",
    "\n",
    "This tutorial uses the [`BART`](http://mrirecon.github.io/bart/) command-line interface (CLI) and presents how to work with 3D Cartesian data using BART, with the goal of implementing a full processing pipeline from raw data to reconstructed image.\n",
    "\n",
    "\n",
    "## Outline\n",
    "1. Bart Setup\n",
    "1. 3D data explortation\n",
    "1. 3D preprocessing\n",
    "1. 3D reconstruction\n",
    "1. 3D postprocessing\n",
    "\n",
    "\n",
    "**Author**: [Jon Tamir](mailto:jtamir@utexas.edu)\n",
    "\n",
    "**Institution**: University of Texas at Austin\n",
    "\n",
    "Based on previous material written by [Moritz Blumenthal](mailto:blumenthal@@tugraz.at) and [H. Christian M. Holme](mailto:Holme@tugraz.at)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 Setup BART\n",
    "This notebook is designed to run on a local system. It uses the python kernel, however, almost all commands use the `%%bash` cell magic to be executed in a `bash` subshell.\n",
    "\n",
    "We will use BART version 0.9.00. In particular, we will take advantage of the newly added looping feature. For more information check the announcement on our [mailing list](https://lists.eecs.berkeley.edu/sympa/arc/mrirecon/2023-12/msg00000.html).\n",
    "\n",
    "\n",
    "This version has been archived at CERN as:  \n",
    "\n",
    "BART: version 0.9.00 (2023) DOI:10.5281/zenodo.10277939"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e5RxFHCDnKGt"
   },
   "source": [
    "### 1.1 Local Usage\n",
    "- Install bart from its [github repository](https://github.com/mrirecon/bart)\n",
    "- Set the `BART_TOOLBOX_PATH` to the BART directory and add it to the `PATH`\n",
    "\n",
    "```bash\n",
    "export BART_TOOLBOX_PATH=/path/to/bart  \n",
    "export PATH=$BART_TOOLBOX_PATH:$PATH\n",
    "```\n",
    "\n",
    "Although the simplest way to call the BART CLI tools is from a terminal, there are also wrapper functions that allow the tools to be used from Matlab and Python. These are located under the `$BART_TOOLBOX_PATH/matlab` and `$BART_TOOLBOX_PATH/python` directories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will also use the [CFL viewer](https://github.com/mrirecon/view). Install it locally after configuring BART"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Clone and compile BART v0.9.00\n",
    "We clone BART into the current working directory of this notebook and delete any previous installation in this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Clone Bart\n",
    "[ -d bart ] && rm -r bart\n",
    "git clone https://github.com/mrirecon/bart/ --branch v0.9.00 bart &> /dev/null\n",
    "\n",
    "cd bart\n",
    "\n",
    "make -j32 &> /dev/null"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Add BART to PATH variable\n",
    "\n",
    "We add the BART directory to the PATH variable and include the python wrapper for reading *.cfl files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ['BART_TOOLBOX_PATH']=os.getcwd()+\"/bart/\"\n",
    "os.environ['PATH'] = os.environ['BART_TOOLBOX_PATH'] + \":\" + os.environ['PATH']\n",
    "sys.path.append(os.environ['BART_TOOLBOX_PATH'] + \"/python/\")\n",
    "os.environ['DEBUG_LEVEL'] = '2'\n",
    "os.environ['BART_DEBUG_LEVEL'] = '2'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check BART setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"# The BART used in this notebook:\"\n",
    "which bart\n",
    "echo \"# BART version: \"\n",
    "bart version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 Install Interactive CFL Viewer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "# Clone Bart\n",
    "[ -d view ] && rm -r view\n",
    "git clone https://github.com/mrirecon/view/ view &> /dev/null\n",
    "\n",
    "cd view\n",
    "\n",
    "make &> /dev/null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['VIEW_TOOLBOX_PATH']=os.getcwd()+\"/view/\"\n",
    "os.environ['PATH'] = os.environ['VIEW_TOOLBOX_PATH'] + \":\" + os.environ['PATH']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check view setup:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"# The BART viewer used in this notebook:\"\n",
    "which view"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.5 Python visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# More python libraries\n",
    "import cfl\n",
    "import numpy as np\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib import cm\n",
    "from mpl_toolkits.axes_grid1 import make_axes_locatable\n",
    "from IPython.display import Image\n",
    "\n",
    "def bart_plot(data, from_cfl=False, title=None, vmin=None, vmax=None, cmap='gray', cbar_label='', mag=True, fsize=10):\n",
    "\n",
    "    # Import data\n",
    "    if from_cfl:\n",
    "        data = cfl.readcfl(data).squeeze()\n",
    "    data = np.abs(data) if mag else data\n",
    "\n",
    "    fig = plt.figure(figsize=(fsize,fsize))\n",
    "    ax1 = fig.add_subplot(111)\n",
    "    im = ax1.imshow(data, interpolation='nearest', cmap=cmap, vmin=vmin, vmax=vmax)\n",
    "    if title:\n",
    "      plt.title(title)\n",
    "    # Style settings\n",
    "    divider = make_axes_locatable(ax1)\n",
    "    cax = divider.append_axes(\"right\", size=\"5%\", pad=0.05)\n",
    "    cbar = plt.colorbar(im, cax=cax)\n",
    "    cbar.set_label(cbar_label)\n",
    "    cbar.ax.tick_params()\n",
    "\n",
    "    ax1.set_yticklabels([])\n",
    "    ax1.set_xticklabels([])\n",
    "    ax1.xaxis.set_ticks_position('none')\n",
    "    ax1.yaxis.set_ticks_position('none')\n",
    "    ax1.set_axis_off()\n",
    "\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 3D Cartesian pre-processing\n",
    "\n",
    "For this tutorial, we will go over the steps involved in reconstructing 3D Cartesian data.\n",
    "\n",
    "Data were scanned on a 3T 750W scanner (GE Healthcare) using a 12-channel head coil. The data were collected with partial Fourier sampling of 75\\% in the phase encode direction using the BRAVO sequence. The parallel imaging acceleration factor was 1.75x1.25.\n",
    "\n",
    "Our goal is to do a fully 3D reconstruction taking advantage of steps that can be split into separate 2D problems. Some steps will naturally require 3D operations.\n",
    "\n",
    "Because the BART file format is simple, it is possible to read data from many different sources. The BART command includes the `twixread` tool for basic reading of Siemens `.dat` files. We also include GE Orchestra libraries for reading P-File and ScanArchives, called [ox-bart](https://github.com/mrirecon/ox-bart).\n",
    "\n",
    "In this part, we have already converted a k-space dataset from the vendor-specific format to BART format. The files are the following:\n",
    "\n",
    "- `ksp`: Raw k-space data\n",
    "- `noise`: Noise pre-scan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### A note on working with 3D data\n",
    "\n",
    "Because of the complexity of 3D data (+ coils), we will want to view the data with a 3D viewer. For this reason, I will use the [BART View Tool](https://github.com/mrirecon/view). This viewer will pop up a new window on my machine.\n",
    "\n",
    "Now, we will often manipulate the data in different ways: perform FFTs, RSS the coil dimension, look at sampling patterns, etc. This means that we will create lots of temporary BART files that may not be needed after a while. When you are working on a machine with a large hard disk, my recommendation is to keep the temporary files until you are ready to write a final, clean script. This leaves a \"paper trail\" for debugging. But if you are low on space, you can delete the files as you go."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Explore the data and correct orientation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download the data\n",
    "The data are stored on Google Drive. You can download it [here](https://drive.google.com/file/d/1JJl1ueJSxyzHYTUUh4YlVdk2g3Ypjcoq/view?usp=sharing) or use the following cell to download it. Save it to the `webinar8` directory and uncompress the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gdown\n",
    "!gdown 1JJl1ueJSxyzHYTUUh4YlVdk2g3Ypjcoq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!tar xvvf data.tgz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yqy9G1UgEmBJ",
    "outputId": "83a65375-512f-4f94-c08c-2225ffd8e0af"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "echo \"ksp:\"\n",
    "bart show -m ksp_raw\n",
    "echo\n",
    "echo \"noise:\"\n",
    "bart show -m noise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on the array sizes and dimensions, we can infer that the readout dimension is 240 samples, the phase encode dimension is 180, the slice encode is 182, and there are 12 coils. Notice that the phase encode dimension is 75\\% of the readout dimension, consistent with the Partial Fourier factor.\n",
    "\n",
    "When working with new data, it is useful to plot it to get a sense of what is going on.\n",
    "Let's print the middle slice on the first coil in the three principal directions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "view ksp_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like our k-space data are not centered due to the Partial Fourier factor. This means we will need to zero-pad the data in order to get it to the correct size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before that, let's take a look at the data in the image domain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart fft -iu $(bart bitmask 0 1 2) ksp_raw cimg_raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "view cimg_raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two \"problems.\"\n",
    "1. The image is flipped in the readout direction! Let's unflip it to keep things consistent\n",
    "2. There is a FOV/2 shift in the slice encode direction. This is common with 3D GE data. Let's correct it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bart flip 1 ksp_raw ksp0\n",
    "bart fftmod $(bart bitmask 2) ksp0 ksp\n",
    "\n",
    "bart fft -iu 7 ksp cimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "view cimg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's better!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Noise prewhitening\n",
    "Modern scanner software versions will provide us with a noise pre-scan. In this case, we have the noise array, which contains 4096 readout samples for each coil. We can use this array to build a noise prewhitening matrix and apply it to the data. Let's look at the original noise covariance matrix of the data using the `bart whiten` tool.\n",
    "\n",
    "```bash\n",
    "Usage: whiten [-o <file>] [-c <file>] [-n] <input> <ndata> <output> [<optmat_out>] [<covar_out>] \n",
    "\n",
    "Apply multi-channel noise pre-whitening on <input> using noise data <ndata>.\n",
    "Optionally output whitening matrix and noise covariance matrix\n",
    "\n",
    "-o <optmat_in>    use external whitening matrix <optmat_in>\n",
    "-c <covar_in>     use external noise covariance matrix <covar_in>\n",
    "-n                normalize variance to 1 using noise data <ndata>\n",
    "-h                help\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart whiten ksp noise ksp_white optmat covar\n",
    "# bart flip 0 ksp ksp_white ### SKIP NOISE PREWHITENING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bart_plot('covar', from_cfl=True, cmap='viridis', title='Noise covariance matrix (before whitening)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a higher amount of noise in the second-to-last channel. Without noise pre-whitening, we will unnecessarily amplify the noise in the reconstruction due to that channel. Effectively, noise pre-whitening lowers the contribution of that noisy channel while also decorrelating the noise across channels.\n",
    "\n",
    "We will continue processing the data, but now working off of the `ksp_white` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Zero-pad by the Partial Fourier factor\n",
    "As we saw earlier, the kspace data were not centered because of the PF factor. Let's go ahead and zero-padd by the factor.\n",
    "\n",
    "We will continue to do all our operations using bash so that at the end we can turn it into a usable script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart pattern ksp_white pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "view pat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dim0=$(bart show -d 0 ksp)\n",
    "echo $dim0\n",
    "\n",
    "bart resize 1 $dim0 ksp_white ksp_white_resize\n",
    "\n",
    "bart show -m ksp_white_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "cat ksp_white_resize.hdr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart pattern ksp_white_resize pat_resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "view pat_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4 Coil Compression\n",
    "To reduce the size of our dataset and therefore also decrease the computational complexity, we perform a coil compression with the `cc` command using the [Geometric Coil Compress (GCC)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3396763/) approach.\n",
    "\n",
    "We will do coil compression in 2 steps. We will first use `cc` on the kspace data to create the coil compression matrix. We will then use `ccapply` to apply it to both the reference data and to the k-space data. This way we use the same coil compression matrix for both arrays.\n",
    "\n",
    "We compress reduce the dataset to 6 virtual coils with `-p`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart cc -h\n",
    "bart ccapply -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart cc -M -G ksp_white_resize cc_mat\n",
    "bart ccapply -G -p 6 ksp_white_resize cc_mat ksp_white_resize_cc\n",
    "\n",
    "bart show -m cc_mat\n",
    "bart show -m ksp_white_resize_cc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ho2Y4N9_PvIs"
   },
   "source": [
    "### 2.6 RSS reconstructions\n",
    "\n",
    "The data were acquired with a modest acceleration factor of `1.75 x 1.25`.  \n",
    "Let's do simple RSS reconstructions of the subsampled data to get a sense of it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 427
    },
    "id": "V-X169uMPzLC",
    "outputId": "ff722e60-05fd-46f6-feec-af36db72d4eb"
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bart fft -iu 7 ksp_white_resize_cc cimg_white_resize_cc\n",
    "bart rss $(bart bitmask 3) cimg_white_resize_cc reco_rss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "view reco_rss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is not very good. The image is corrupted with aliasing artifacts due to the equispaced subsampling. There is also a slight blur in the phase encode direction due to the Partial Fourier sampling.\n",
    "\n",
    "Moving on!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vMR9HvyLv7RN"
   },
   "source": [
    "### 2.7 Coil Sensitivity Estimation\n",
    "\n",
    "We use the ESPIRiT algorithm to obtain the coil sensitivity profiles. We will now take a closer look at the ESPIRiT `ecalib` tool."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart ecalib -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The default number of maps is 2. It's often a good idea to use 2 maps for reconstruction of clinical data, as it's possible that there are slight inconsistencies either due to the scan prescription or motion.\n",
    "\n",
    "Notice that the ecalib tool has a `-1` option. ESPIRiT has two disctinct steps:\n",
    "1. Estimate the signal/noise subspaces by performing an SVD of the calibration matrix derived from the ACS region\n",
    "1. Estimate the eigenvectors/eigenvalues by performing EVD on a per-pixel basis; these form the sensitivity maps\n",
    "\n",
    "Step 1 requires the full ACS region. Step 2 is \"embarassingly parallel\", meaning that each pixel (or slice) can be computed separately.\n",
    "\n",
    "Now, if we plan to use a single machine for reconstruction, it is not too important to split these steps. Just run `ecalib` and both steps will be performed. Step 1 will use all the available CPU cores to perform the SVD. Step 2 will distribute the EVD on a slice-by-slice basis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bart ecalib -1 ksp_white_resize_cc calone\n",
    "bart show -m calone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bart ecaltwo -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "dim0=$(bart show -d 0 ksp_white_resize_cc)\n",
    "dim1=$(bart show -d 1 ksp_white_resize_cc)\n",
    "dim2=$(bart show -d 2 ksp_white_resize_cc)\n",
    "bart ecaltwo -S -m2 $dim0 $dim1 $dim2 calone sens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "view sens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3AxOykoMwTps"
   },
   "source": [
    "## 3 Parallel imaging reconstruction\n",
    "We are now ready to do a parallel imaging reconstruction. \n",
    "\n",
    "Given the sensitivities, we can use the `pics` command to perform iterative parallel imaging reconstruction using various regularization terms. It solves the folllowing minimization problem:\n",
    "\n",
    "$\\arg\\min_x ||PFS x - y|| + \\lambda R(x)$, where:\n",
    "- $P$ is the sampling operator\n",
    "- $F$ is the Fourier transform\n",
    "- $S$ is the multiplication with the sensitivity maps\n",
    "- $x$ is the unknown image\n",
    "- $y$ are the acquired multi-coil k-space data\n",
    "- $R$ is a regularization functional\n",
    "- $\\lambda$ is the regularization weighting parameter\n",
    "\n",
    "A popular regularization is $\\ell_2$, i.e. $R(x) = ||x||_2^2$.\n",
    "\n",
    "The objective function then corresponds to a SENSE reconstruction. We will use `pics` with l2 regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart pics -h\n",
    "\n",
    "bart pics -Rh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Slice-by-slice PICS\n",
    "\n",
    "Now, because the data are 3D Cartesian, the data are fully sampled in the readout direction. This means that there is only a small benefit to performing a full 3D reconstruction, at the cost of computation time.\n",
    "\n",
    "Instead, we will perform PICS reconstruction in a slice-by-slice manner. The steps we will take are the following:\n",
    "1. Perform an IFFT in the readout direction to decouple the readout slices\n",
    "1. Perform a PICS reconstruction of each slice independently (in parallel)\n",
    "1. Rejoin the data\n",
    "\n",
    "Fortunately, Steps 2-3 can now be automated using BART v0.9.00's new looping feature.\n",
    "\n",
    "There is one caveat: PICS will automatically scale the data to roughly the range [0, 1], so that the regularization parameter can be chosen in a similar range for different datasets. If we reconstruct each slice separately, the scale factor will differ.\n",
    "\n",
    "To have a relatively consistent regularization, we will want to scale each slice by the same scale factor. We will run one iteration of 3D pics to get the scale factor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "bart fft -iu 1 ksp_white_resize_cc ksp_white_resize_cc_fft"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart pics -d4 -i 0 ksp_white_resize_cc sens reco_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%bash\n",
    "\n",
    "scale_factor=$(bart pics -d4 -i 0 ksp_white_resize_cc sens reco_l2 | grep Scaling |  awk  '{print $2}')\n",
    "export scale_factor=${scale_factor::-1}\n",
    "echo \"Reconstruction scale factor: $scale_factor\"\n",
    "\n",
    "lambda=.0015\n",
    "debug_level=0\n",
    "\n",
    "view reco_l2 &\n",
    "\n",
    "bart --parallel-loop 1 -r ksp_white_resize_cc_fft -t 80 \\\n",
    "    pics -w ${scale_factor} -S -R Q:${lambda} -d ${debug_level} \\\n",
    "        ksp_white_resize_cc_fft sens reco_l2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "view reco_l2 &"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Post-processing\n",
    "\n",
    "The reconstruction looks pretty good! However, you may notice that it is a little blurry in the phase encode direction due to the PF factor.\n",
    "\n",
    "There is also a second image because we reconstructed with two maps. There is no \"right answer\" for dealing with the second map, as it can be quite application-dependent. We will choose to combine the second map by going through the coil operator, and then perform homodyne correction on each channel indepdently. Finally, we will coil-combine with an RSS operation.\n",
    "\n",
    "For the last step, we will perform homodyne correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart show -m reco_l2\n",
    "bart fmac -s $(bart bitmask 4) reco_l2 sens reco_l2_cimg\n",
    "bart show -m reco_l2_cimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "view reco_l2_cimg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart homodyne -h"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The homodyne command can take optional arguments like a phase reference and an offset ramp filter. It can also save some operations if the data are already Fourier transformed or uncentered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "bart homodyne -I 1 0.75 reco_l2_cimg reco_l2_cimg_homodyne\n",
    "bart rss 8 reco_l2_cimg_homodyne reco_l2_homodyne"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "view reco_l2_homodyne &\n",
    "view reco_l2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Thank you for attending!__"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "e5RxFHCDnKGt"
   ],
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
